{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">\n",
    "<div dir='rtl'>\n",
    "\n",
    "<b> نام و نام‌‌خانوادگی: سید احسان حسن بیگی</b>\n",
    "\n",
    "<b> شماره دانشجویی: ۴۰۲۲۱۱۷۲۳</b>\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir='rtl'>\n",
    "<h1> \n",
    "مقدمه\n",
    "</h1>\n",
    "<p>\n",
    "در این تمرین قصد داریم به مباحث زیر بپردازیم:\n",
    "<li> کاهش ابعاد </li>\n",
    "<li> خوشه‌بندی متن و هرس‌کردن خوشه‌ها</li>\n",
    "\n",
    "کتابخانه‌های مورد نظرتان را هم می‌توانید در اولین سل نوت‌بوک فراخوانی کنید. \n",
    "\n",
    "تمرین درباره ی خوشه بندی اهنگ های مشابه در اپ اسپاتیفای است که از دیتاستی از سایت کگل برداشته شده است.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<h1>\n",
    "لود دیتا</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "در این بخش باید دیتا را لود کرده و در انتها فقط نام آهنگ و فیچر هایی که به نظرتان مفید است را با ذکر علتی کوتاه نگه دارید. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['track_name', 'track_artist', 'track_popularity', 'track_album_name',\n",
      "       'track_album_release_date', 'playlist_genre', 'playlist_subgenre',\n",
      "       'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness',\n",
      "       'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
      "       'duration_ms'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"datasets/spotify.csv\")\n",
    "data = data.dropna()\n",
    "\n",
    "# merge rows with the same 'track_id' and replace numeric columns with the mean\n",
    "# replace numeric columns with the mean\n",
    "# replace non-numeric columns with the most frequent value\n",
    "# numeric_columns = data.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "# non_numeric_columns = data.select_dtypes(exclude=[\"number\"]).columns.tolist()\n",
    "# data = data.groupby(\"track_id\", as_index=False).agg(\n",
    "#     {\n",
    "#         **{col: \"mean\" for col in numeric_columns},\n",
    "#         **{col: lambda x: x.mode().iloc[0] for col in non_numeric_columns},\n",
    "#     }\n",
    "# )\n",
    "\n",
    "garbage_cols = [\"track_id\", \"track_album_id\", \"playlist_id\", \"playlist_name\"]\n",
    "data = data.drop(columns=garbage_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numeric_columns = data.select_dtypes(exclude=[\"number\"]).columns.tolist()\n",
    "for col in non_numeric_columns:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "    if col == 'track_name':\n",
    "        track_name_le = le\n",
    "\n",
    "# data['track_name'] = track_name_le.inverse_transform(data['track_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "توضیح دهید که دیتای scale نشده چه مشکلی میتواند برای خوشه بندی ایجاد کند?\n",
    "<br>\n",
    "در این cell باید یک standard scalar را از صفر پیاده سازی نمایید. تا برای قسمت های بعدی یک دیتای مناسب داشته باشید.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardization\n",
    "def standard_scalar(df, numeric_columns=None):\n",
    "    if numeric_columns is None:\n",
    "        numeric_columns = df.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "\n",
    "    column_stats = {}\n",
    "    for col in numeric_columns:\n",
    "        mean = df[numeric_columns][col].mean()\n",
    "        std = df[numeric_columns][col].std()\n",
    "        column_stats[col] = {'mean': mean, 'std': std}\n",
    "\n",
    "        df[col] = (df[col] - mean) / std\n",
    "\n",
    "    return df, column_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<h1>\n",
    "کاهش ابعاد\n",
    "</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "یکی از روش‌های کاهش ابعاد، PCA است. با استفاده از پیاده‌سازی آن در کتابخانه sklearn، ابعاد ویژگی‌ را کاهش دهید.\n",
    "<br>\n",
    "سپس با استفاده از explained_variance_ratio_ در الگوریتم PCA  نشان دهید که با وجود یک ترشولد مناسب  تا چه میزان میتوان ابعاد ویژگی ها را کم تر کرد.\n",
    "<br>\n",
    "برای ترشولدی که انتخاب کردید دلیل بیاورید و شهود این متغیر را توضیح دهید.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dimension(embedding, n_components):\n",
    "    \"\"\"\n",
    "    Performs dimensional reduction using PCA with n components left behind\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    embeddings : List\n",
    "        A list of embeddings of documents\n",
    "    \n",
    "    n_components: int\n",
    "        Number of components to keep\n",
    "\n",
    "    Returns a list of reduced embeddings\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components)\n",
    "    pca.fit(embedding)\n",
    "    return pca.transform(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'dtypes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m column_data_types \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtypes\u001b[49m\n\u001b[1;32m      2\u001b[0m data_type_counts \u001b[38;5;241m=\u001b[39m column_data_types\u001b[38;5;241m.\u001b[39mvalue_counts()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(data_type_counts)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'dtypes'"
     ]
    }
   ],
   "source": [
    "column_data_types = data.dtypes\n",
    "data_type_counts = column_data_types.value_counts()\n",
    "print(data_type_counts)\n",
    "\n",
    "# print(data.columns)\n",
    "# print(reduce_dimension(data, .95))\n",
    "# print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Findout the most reduced dimension which has a high cutoff explained variance. Write down the value of cut off and explain it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<h2>\n",
    "خوشه‌بندی\n",
    "</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "در این قسمت، شما ابتدا الگوریتم خوشه‌بندی K-means را \n",
    "<u><b>از پایه</b></u>\n",
    " پیاده‌سازی می‌کنید.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cluster_kmeans(emb_vecs, n_clusters):\n",
    "    \"\"\"\n",
    "    Clusters input vectors using K-means method\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    emb_vecs : List\n",
    "        A list of vectors\n",
    "    \n",
    "    n_clusters: int\n",
    "        Number of clusters\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        Two lists: 1) A list containing cluster centers 2) A list containing cluster index for each input vector\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement K-means method from scratch\n",
    "    # You can't use sklearn.cluster.KMeans for clustering\n",
    "    # implement kmeans clustering here\n",
    "    emb_matrix = None\n",
    "\n",
    "    # Randomly initialize centroids\n",
    "    initial_centroids = None\n",
    "\n",
    "    for _ in range(None):  # You can adjust the number of iterations\n",
    "        # Compute distances between data points and centroids\n",
    "        distances = None\n",
    "\n",
    "        # Assign each point to the closest centroid\n",
    "        cluster_indices = None\n",
    "\n",
    "        # Update centroids\n",
    "        new_centroids = []\n",
    "        \n",
    "\n",
    "    return initial_centroids.tolist(), cluster_indices.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    " با استفاده از K-Means خوشه‌ها را ایجاد کنید. الگوریتم را با استفاده از چند مقدار مختلف تعداد خوشه‌ها (k) اجرا کنید. در هربار اجرا، با استفاده از تعدادی از اسناد موجود در هر خوشه، موضوع آن خوشه را تعیین کرده و خوشه‌بندی حاصله را با استفاده از بردار‌های دوبعدی قسمت قبل، رسم کنید. با اینکار، پیاده‌سازی خود و همچنین کارایی این الگوریتم در خوشه‌بندی اسناد و قرار دادن اسناد مشابه در خوشه‌های یکسان را بررسی کنید.\n",
    "<br>\n",
    "\n",
    " نمودار silhouette score برای مقدار‌های مختلف k را رسم کرده و silhouette analysis برای انتخاب k مناسب انجام دهید. \n",
    "<br>\n",
    "همچنین Within-Cluster Sum of Squares (WSS) را نیز محاسبه کرده و در نهایت این دو کار بهترین مقدار k  را بدست بیاورید.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def wss_score():\n",
    "    #TODO\n",
    "    pass\n",
    "\n",
    "def silhouette_score():\n",
    "    #TODO\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate silhouette score and wss score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot silhouette score for different value of k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: plot wss for different value of k "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "با استفاده از نمودارهای رسم شده توضیح دهید بهترین k برای انتخاب در داده ما با استفاده از الگوریتم K-Means چیست؟\n",
    "چرا؟\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">#TODO: Write your answer in here.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<h2>\n",
    "بررسی خروجی</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "در این قسمت برای اینکه ببینیم چقدر خوب خوشه بندی را انجام داده ایم, از یک روش sample check و نیز TSNE استفاده خواهیم کرد.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "در ابتدا به صورت رندوم از هر خوشه دو اهنگ را انتخاب کرده (با توجه به اینکه در بخش اول بایستی اسم اهنگ را نیز نگه میداشتید) و ببینید واقعا این اهنگ ها به هم نزدیک هستند یا خیر.\n",
    "نکته اینکه صرفا بررسی این عمل نمره دارد و نیازی به خیلی دقیق بودن خروجی نیست.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Sample 2 songs from each cluster and compare them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "با استفاده از این T-SNE و کاهش ابعاد به 2 بعد نشان دهید که ایا خوشه بنده به خوبی انجام شده است یا خیر.\n",
    "\n",
    "</br>\n",
    "در صورت پیاده سازی تابع tsne  از ابتدا, نمره ی امتیازی به شما تعلق خواهد گرفت.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Visualize the clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus TODO: Implement TSNE from scratch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
